{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26df1ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc5be02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "para =  \"\"\"I have three visions for India. \n",
    "           In 3000 years of our history, people from all over the world have come and invaded us, captured our lands, conquered our minds.\n",
    "           From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British, the French, the Dutch, all of them came and looted us, took over what was ours. \n",
    "           Yet we have not done this to any other nation. We have not conquered anyone. \n",
    "           We have not grabbed their land, their culture, their history and tried to enforce our way of life on them.\n",
    "           Why? Because we respect the freedom of others.\n",
    "           That is why my first vision is that of freedom. \n",
    "           I believe that India got its first vision of this in 1857, when we started the War of Independence. \n",
    "           It is this freedom that we must protect and nurture and build on. \n",
    "           If we are not free, no one will respect us.\n",
    "           My second vision for India’s development.\n",
    "           For fifty years we have been a developing nation. \n",
    "           It is time we see ourselves as a developed nation.\n",
    "           We are among the top 5 nations of the world in terms of GDP.\n",
    "           We have a 10 percent growth rate in most areas.\n",
    "           Our poverty levels are falling.\n",
    "           Our achievements are being globally recognised today. \n",
    "           Yet we lack the self-confidence to see ourselves as a developed nation, self-reliant and self-assured.\n",
    "           Isn’t this incorrect?\n",
    "           I have a third vision. \n",
    "           India must stand up to the world. \n",
    "           Because I believe that unless India stands up to the world, no one will respect us.\n",
    "           Only strength respects strength. \n",
    "           We must be strong not only as a military power but also as an economic power. \n",
    "           Both must go hand-in-hand.\n",
    "           My good fortune was to have worked with three great minds. \n",
    "           Dr. Vikram Sarabhai of the Dept. of space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.\n",
    "           I was lucky to have worked with all three of them closely and consider this the great opportunity of my life. \n",
    "           I see four milestones in my career.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b398d7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts([para])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7c3ccff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'of': 2,\n",
       " 'we': 3,\n",
       " 'have': 4,\n",
       " 'and': 5,\n",
       " 'to': 6,\n",
       " 'i': 7,\n",
       " 'in': 8,\n",
       " 'our': 9,\n",
       " 'a': 10,\n",
       " 'not': 11,\n",
       " 'this': 12,\n",
       " 'that': 13,\n",
       " 'my': 14,\n",
       " 'india': 15,\n",
       " 'world': 16,\n",
       " 'us': 17,\n",
       " 'nation': 18,\n",
       " 'is': 19,\n",
       " 'vision': 20,\n",
       " 'must': 21,\n",
       " 'are': 22,\n",
       " 'as': 23,\n",
       " 'three': 24,\n",
       " 'for': 25,\n",
       " 'all': 26,\n",
       " 'them': 27,\n",
       " 'was': 28,\n",
       " 'their': 29,\n",
       " 'respect': 30,\n",
       " 'freedom': 31,\n",
       " 'see': 32,\n",
       " 'self': 33,\n",
       " 'years': 34,\n",
       " 'history': 35,\n",
       " 'from': 36,\n",
       " 'over': 37,\n",
       " 'conquered': 38,\n",
       " 'minds': 39,\n",
       " 'yet': 40,\n",
       " 'life': 41,\n",
       " 'on': 42,\n",
       " 'why': 43,\n",
       " 'because': 44,\n",
       " 'first': 45,\n",
       " 'believe': 46,\n",
       " 'it': 47,\n",
       " 'no': 48,\n",
       " 'one': 49,\n",
       " 'will': 50,\n",
       " 'ourselves': 51,\n",
       " 'developed': 52,\n",
       " 'up': 53,\n",
       " 'only': 54,\n",
       " 'strength': 55,\n",
       " 'power': 56,\n",
       " 'hand': 57,\n",
       " 'worked': 58,\n",
       " 'with': 59,\n",
       " 'great': 60,\n",
       " 'dr': 61,\n",
       " 'visions': 62,\n",
       " '3000': 63,\n",
       " 'people': 64,\n",
       " 'come': 65,\n",
       " 'invaded': 66,\n",
       " 'captured': 67,\n",
       " 'lands': 68,\n",
       " 'alexander': 69,\n",
       " 'onwards': 70,\n",
       " 'greeks': 71,\n",
       " 'turks': 72,\n",
       " 'moguls': 73,\n",
       " 'portuguese': 74,\n",
       " 'british': 75,\n",
       " 'french': 76,\n",
       " 'dutch': 77,\n",
       " 'came': 78,\n",
       " 'looted': 79,\n",
       " 'took': 80,\n",
       " 'what': 81,\n",
       " 'ours': 82,\n",
       " 'done': 83,\n",
       " 'any': 84,\n",
       " 'other': 85,\n",
       " 'anyone': 86,\n",
       " 'grabbed': 87,\n",
       " 'land': 88,\n",
       " 'culture': 89,\n",
       " 'tried': 90,\n",
       " 'enforce': 91,\n",
       " 'way': 92,\n",
       " 'others': 93,\n",
       " 'got': 94,\n",
       " 'its': 95,\n",
       " '1857': 96,\n",
       " 'when': 97,\n",
       " 'started': 98,\n",
       " 'war': 99,\n",
       " 'independence': 100,\n",
       " 'protect': 101,\n",
       " 'nurture': 102,\n",
       " 'build': 103,\n",
       " 'if': 104,\n",
       " 'free': 105,\n",
       " 'second': 106,\n",
       " 'india’s': 107,\n",
       " 'development': 108,\n",
       " 'fifty': 109,\n",
       " 'been': 110,\n",
       " 'developing': 111,\n",
       " 'time': 112,\n",
       " 'among': 113,\n",
       " 'top': 114,\n",
       " '5': 115,\n",
       " 'nations': 116,\n",
       " 'terms': 117,\n",
       " 'gdp': 118,\n",
       " '10': 119,\n",
       " 'percent': 120,\n",
       " 'growth': 121,\n",
       " 'rate': 122,\n",
       " 'most': 123,\n",
       " 'areas': 124,\n",
       " 'poverty': 125,\n",
       " 'levels': 126,\n",
       " 'falling': 127,\n",
       " 'achievements': 128,\n",
       " 'being': 129,\n",
       " 'globally': 130,\n",
       " 'recognised': 131,\n",
       " 'today': 132,\n",
       " 'lack': 133,\n",
       " 'confidence': 134,\n",
       " 'reliant': 135,\n",
       " 'assured': 136,\n",
       " 'isn’t': 137,\n",
       " 'incorrect': 138,\n",
       " 'third': 139,\n",
       " 'stand': 140,\n",
       " 'unless': 141,\n",
       " 'stands': 142,\n",
       " 'respects': 143,\n",
       " 'be': 144,\n",
       " 'strong': 145,\n",
       " 'military': 146,\n",
       " 'but': 147,\n",
       " 'also': 148,\n",
       " 'an': 149,\n",
       " 'economic': 150,\n",
       " 'both': 151,\n",
       " 'go': 152,\n",
       " 'good': 153,\n",
       " 'fortune': 154,\n",
       " 'vikram': 155,\n",
       " 'sarabhai': 156,\n",
       " 'dept': 157,\n",
       " 'space': 158,\n",
       " 'professor': 159,\n",
       " 'satish': 160,\n",
       " 'dhawan': 161,\n",
       " 'who': 162,\n",
       " 'succeeded': 163,\n",
       " 'him': 164,\n",
       " 'brahm': 165,\n",
       " 'prakash': 166,\n",
       " 'father': 167,\n",
       " 'nuclear': 168,\n",
       " 'material': 169,\n",
       " 'lucky': 170,\n",
       " 'closely': 171,\n",
       " 'consider': 172,\n",
       " 'opportunity': 173,\n",
       " 'four': 174,\n",
       " 'milestones': 175,\n",
       " 'career': 176}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60843785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7, 4, 24, 62, 25, 15]]\n",
      "[[8, 63, 34, 2, 9, 35, 64, 36, 26, 37, 1, 16, 4, 65, 5, 66, 17, 67, 9, 68, 38, 9, 39]]\n",
      "[[36, 69, 70, 1, 71, 1, 72, 1, 73, 1, 74, 1, 75, 1, 76, 1, 77, 26, 2, 27, 78, 5, 79, 17, 80, 37, 81, 28, 82]]\n",
      "[[40, 3, 4, 11, 83, 12, 6, 84, 85, 18, 3, 4, 11, 38, 86]]\n",
      "[[3, 4, 11, 87, 29, 88, 29, 89, 29, 35, 5, 90, 6, 91, 9, 92, 2, 41, 42, 27]]\n",
      "[[43, 44, 3, 30, 1, 31, 2, 93]]\n",
      "[[13, 19, 43, 14, 45, 20, 19, 13, 2, 31]]\n",
      "[[7, 46, 13, 15, 94, 95, 45, 20, 2, 12, 8, 96, 97, 3, 98, 1, 99, 2, 100]]\n",
      "[[47, 19, 12, 31, 13, 3, 21, 101, 5, 102, 5, 103, 42]]\n",
      "[[104, 3, 22, 11, 105, 48, 49, 50, 30, 17]]\n",
      "[[14, 106, 20, 25, 107, 108]]\n",
      "[[25, 109, 34, 3, 4, 110, 10, 111, 18]]\n",
      "[[47, 19, 112, 3, 32, 51, 23, 10, 52, 18]]\n",
      "[[3, 22, 113, 1, 114, 115, 116, 2, 1, 16, 8, 117, 2, 118]]\n",
      "[[3, 4, 10, 119, 120, 121, 122, 8, 123, 124]]\n",
      "[[9, 125, 126, 22, 127]]\n",
      "[[9, 128, 22, 129, 130, 131, 132]]\n",
      "[[40, 3, 133, 1, 33, 134, 6, 32, 51, 23, 10, 52, 18, 33, 135, 5, 33, 136]]\n",
      "[[137, 12, 138]]\n",
      "[[7, 4, 10, 139, 20]]\n",
      "[[15, 21, 140, 53, 6, 1, 16]]\n",
      "[[44, 7, 46, 13, 141, 15, 142, 53, 6, 1, 16, 48, 49, 50, 30, 17]]\n",
      "[[54, 55, 143, 55]]\n",
      "[[3, 21, 144, 145, 11, 54, 23, 10, 146, 56, 147, 148, 23, 149, 150, 56]]\n",
      "[[151, 21, 152, 57, 8, 57]]\n",
      "[[14, 153, 154, 28, 6, 4, 58, 59, 24, 60, 39]]\n",
      "[[61, 155, 156, 2, 1, 157, 2, 158, 159, 160, 161, 162, 163, 164, 5, 61, 165, 166, 167, 2, 168, 169]]\n",
      "[[7, 28, 170, 6, 4, 58, 59, 26, 24, 2, 27, 171, 5, 172, 12, 1, 60, 173, 2, 14, 41]]\n",
      "[[7, 32, 174, 175, 8, 14, 176]]\n"
     ]
    }
   ],
   "source": [
    "for sentences in para.split('\\n'):\n",
    "    print(tokenizer.texts_to_sequences([sentences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09380c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representing sentences into numbers sequences\n",
    "\n",
    "input_sequences = []\n",
    "for sentences in para.split('\\n'):\n",
    "    tokenized_sentence = tokenizer.texts_to_sequences([sentences])[0]\n",
    "    \n",
    "    for i in range(1,len(tokenized_sentence)):\n",
    "        input_sequences.append(tokenized_sentence[:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3978da8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7, 4],\n",
       " [7, 4, 24],\n",
       " [7, 4, 24, 62],\n",
       " [7, 4, 24, 62, 25],\n",
       " [7, 4, 24, 62, 25, 15],\n",
       " [8, 63],\n",
       " [8, 63, 34],\n",
       " [8, 63, 34, 2],\n",
       " [8, 63, 34, 2, 9],\n",
       " [8, 63, 34, 2, 9, 35],\n",
       " [8, 63, 34, 2, 9, 35, 64],\n",
       " [8, 63, 34, 2, 9, 35, 64, 36],\n",
       " [8, 63, 34, 2, 9, 35, 64, 36, 26],\n",
       " [8, 63, 34, 2, 9, 35, 64, 36, 26, 37],\n",
       " [8, 63, 34, 2, 9, 35, 64, 36, 26, 37, 1],\n",
       " [8, 63, 34, 2, 9, 35, 64, 36, 26, 37, 1, 16],\n",
       " [8, 63, 34, 2, 9, 35, 64, 36, 26, 37, 1, 16, 4],\n",
       " [8, 63, 34, 2, 9, 35, 64, 36, 26, 37, 1, 16, 4, 65],\n",
       " [8, 63, 34, 2, 9, 35, 64, 36, 26, 37, 1, 16, 4, 65, 5],\n",
       " [8, 63, 34, 2, 9, 35, 64, 36, 26, 37, 1, 16, 4, 65, 5, 66],\n",
       " [8, 63, 34, 2, 9, 35, 64, 36, 26, 37, 1, 16, 4, 65, 5, 66, 17],\n",
       " [8, 63, 34, 2, 9, 35, 64, 36, 26, 37, 1, 16, 4, 65, 5, 66, 17, 67],\n",
       " [8, 63, 34, 2, 9, 35, 64, 36, 26, 37, 1, 16, 4, 65, 5, 66, 17, 67, 9],\n",
       " [8, 63, 34, 2, 9, 35, 64, 36, 26, 37, 1, 16, 4, 65, 5, 66, 17, 67, 9, 68],\n",
       " [8, 63, 34, 2, 9, 35, 64, 36, 26, 37, 1, 16, 4, 65, 5, 66, 17, 67, 9, 68, 38],\n",
       " [8,\n",
       "  63,\n",
       "  34,\n",
       "  2,\n",
       "  9,\n",
       "  35,\n",
       "  64,\n",
       "  36,\n",
       "  26,\n",
       "  37,\n",
       "  1,\n",
       "  16,\n",
       "  4,\n",
       "  65,\n",
       "  5,\n",
       "  66,\n",
       "  17,\n",
       "  67,\n",
       "  9,\n",
       "  68,\n",
       "  38,\n",
       "  9],\n",
       " [8,\n",
       "  63,\n",
       "  34,\n",
       "  2,\n",
       "  9,\n",
       "  35,\n",
       "  64,\n",
       "  36,\n",
       "  26,\n",
       "  37,\n",
       "  1,\n",
       "  16,\n",
       "  4,\n",
       "  65,\n",
       "  5,\n",
       "  66,\n",
       "  17,\n",
       "  67,\n",
       "  9,\n",
       "  68,\n",
       "  38,\n",
       "  9,\n",
       "  39],\n",
       " [36, 69],\n",
       " [36, 69, 70],\n",
       " [36, 69, 70, 1],\n",
       " [36, 69, 70, 1, 71],\n",
       " [36, 69, 70, 1, 71, 1],\n",
       " [36, 69, 70, 1, 71, 1, 72],\n",
       " [36, 69, 70, 1, 71, 1, 72, 1],\n",
       " [36, 69, 70, 1, 71, 1, 72, 1, 73],\n",
       " [36, 69, 70, 1, 71, 1, 72, 1, 73, 1],\n",
       " [36, 69, 70, 1, 71, 1, 72, 1, 73, 1, 74],\n",
       " [36, 69, 70, 1, 71, 1, 72, 1, 73, 1, 74, 1],\n",
       " [36, 69, 70, 1, 71, 1, 72, 1, 73, 1, 74, 1, 75],\n",
       " [36, 69, 70, 1, 71, 1, 72, 1, 73, 1, 74, 1, 75, 1],\n",
       " [36, 69, 70, 1, 71, 1, 72, 1, 73, 1, 74, 1, 75, 1, 76],\n",
       " [36, 69, 70, 1, 71, 1, 72, 1, 73, 1, 74, 1, 75, 1, 76, 1],\n",
       " [36, 69, 70, 1, 71, 1, 72, 1, 73, 1, 74, 1, 75, 1, 76, 1, 77],\n",
       " [36, 69, 70, 1, 71, 1, 72, 1, 73, 1, 74, 1, 75, 1, 76, 1, 77, 26],\n",
       " [36, 69, 70, 1, 71, 1, 72, 1, 73, 1, 74, 1, 75, 1, 76, 1, 77, 26, 2],\n",
       " [36, 69, 70, 1, 71, 1, 72, 1, 73, 1, 74, 1, 75, 1, 76, 1, 77, 26, 2, 27],\n",
       " [36, 69, 70, 1, 71, 1, 72, 1, 73, 1, 74, 1, 75, 1, 76, 1, 77, 26, 2, 27, 78],\n",
       " [36,\n",
       "  69,\n",
       "  70,\n",
       "  1,\n",
       "  71,\n",
       "  1,\n",
       "  72,\n",
       "  1,\n",
       "  73,\n",
       "  1,\n",
       "  74,\n",
       "  1,\n",
       "  75,\n",
       "  1,\n",
       "  76,\n",
       "  1,\n",
       "  77,\n",
       "  26,\n",
       "  2,\n",
       "  27,\n",
       "  78,\n",
       "  5],\n",
       " [36,\n",
       "  69,\n",
       "  70,\n",
       "  1,\n",
       "  71,\n",
       "  1,\n",
       "  72,\n",
       "  1,\n",
       "  73,\n",
       "  1,\n",
       "  74,\n",
       "  1,\n",
       "  75,\n",
       "  1,\n",
       "  76,\n",
       "  1,\n",
       "  77,\n",
       "  26,\n",
       "  2,\n",
       "  27,\n",
       "  78,\n",
       "  5,\n",
       "  79],\n",
       " [36,\n",
       "  69,\n",
       "  70,\n",
       "  1,\n",
       "  71,\n",
       "  1,\n",
       "  72,\n",
       "  1,\n",
       "  73,\n",
       "  1,\n",
       "  74,\n",
       "  1,\n",
       "  75,\n",
       "  1,\n",
       "  76,\n",
       "  1,\n",
       "  77,\n",
       "  26,\n",
       "  2,\n",
       "  27,\n",
       "  78,\n",
       "  5,\n",
       "  79,\n",
       "  17],\n",
       " [36,\n",
       "  69,\n",
       "  70,\n",
       "  1,\n",
       "  71,\n",
       "  1,\n",
       "  72,\n",
       "  1,\n",
       "  73,\n",
       "  1,\n",
       "  74,\n",
       "  1,\n",
       "  75,\n",
       "  1,\n",
       "  76,\n",
       "  1,\n",
       "  77,\n",
       "  26,\n",
       "  2,\n",
       "  27,\n",
       "  78,\n",
       "  5,\n",
       "  79,\n",
       "  17,\n",
       "  80],\n",
       " [36,\n",
       "  69,\n",
       "  70,\n",
       "  1,\n",
       "  71,\n",
       "  1,\n",
       "  72,\n",
       "  1,\n",
       "  73,\n",
       "  1,\n",
       "  74,\n",
       "  1,\n",
       "  75,\n",
       "  1,\n",
       "  76,\n",
       "  1,\n",
       "  77,\n",
       "  26,\n",
       "  2,\n",
       "  27,\n",
       "  78,\n",
       "  5,\n",
       "  79,\n",
       "  17,\n",
       "  80,\n",
       "  37],\n",
       " [36,\n",
       "  69,\n",
       "  70,\n",
       "  1,\n",
       "  71,\n",
       "  1,\n",
       "  72,\n",
       "  1,\n",
       "  73,\n",
       "  1,\n",
       "  74,\n",
       "  1,\n",
       "  75,\n",
       "  1,\n",
       "  76,\n",
       "  1,\n",
       "  77,\n",
       "  26,\n",
       "  2,\n",
       "  27,\n",
       "  78,\n",
       "  5,\n",
       "  79,\n",
       "  17,\n",
       "  80,\n",
       "  37,\n",
       "  81],\n",
       " [36,\n",
       "  69,\n",
       "  70,\n",
       "  1,\n",
       "  71,\n",
       "  1,\n",
       "  72,\n",
       "  1,\n",
       "  73,\n",
       "  1,\n",
       "  74,\n",
       "  1,\n",
       "  75,\n",
       "  1,\n",
       "  76,\n",
       "  1,\n",
       "  77,\n",
       "  26,\n",
       "  2,\n",
       "  27,\n",
       "  78,\n",
       "  5,\n",
       "  79,\n",
       "  17,\n",
       "  80,\n",
       "  37,\n",
       "  81,\n",
       "  28],\n",
       " [36,\n",
       "  69,\n",
       "  70,\n",
       "  1,\n",
       "  71,\n",
       "  1,\n",
       "  72,\n",
       "  1,\n",
       "  73,\n",
       "  1,\n",
       "  74,\n",
       "  1,\n",
       "  75,\n",
       "  1,\n",
       "  76,\n",
       "  1,\n",
       "  77,\n",
       "  26,\n",
       "  2,\n",
       "  27,\n",
       "  78,\n",
       "  5,\n",
       "  79,\n",
       "  17,\n",
       "  80,\n",
       "  37,\n",
       "  81,\n",
       "  28,\n",
       "  82],\n",
       " [40, 3],\n",
       " [40, 3, 4],\n",
       " [40, 3, 4, 11],\n",
       " [40, 3, 4, 11, 83],\n",
       " [40, 3, 4, 11, 83, 12],\n",
       " [40, 3, 4, 11, 83, 12, 6],\n",
       " [40, 3, 4, 11, 83, 12, 6, 84],\n",
       " [40, 3, 4, 11, 83, 12, 6, 84, 85],\n",
       " [40, 3, 4, 11, 83, 12, 6, 84, 85, 18],\n",
       " [40, 3, 4, 11, 83, 12, 6, 84, 85, 18, 3],\n",
       " [40, 3, 4, 11, 83, 12, 6, 84, 85, 18, 3, 4],\n",
       " [40, 3, 4, 11, 83, 12, 6, 84, 85, 18, 3, 4, 11],\n",
       " [40, 3, 4, 11, 83, 12, 6, 84, 85, 18, 3, 4, 11, 38],\n",
       " [40, 3, 4, 11, 83, 12, 6, 84, 85, 18, 3, 4, 11, 38, 86],\n",
       " [3, 4],\n",
       " [3, 4, 11],\n",
       " [3, 4, 11, 87],\n",
       " [3, 4, 11, 87, 29],\n",
       " [3, 4, 11, 87, 29, 88],\n",
       " [3, 4, 11, 87, 29, 88, 29],\n",
       " [3, 4, 11, 87, 29, 88, 29, 89],\n",
       " [3, 4, 11, 87, 29, 88, 29, 89, 29],\n",
       " [3, 4, 11, 87, 29, 88, 29, 89, 29, 35],\n",
       " [3, 4, 11, 87, 29, 88, 29, 89, 29, 35, 5],\n",
       " [3, 4, 11, 87, 29, 88, 29, 89, 29, 35, 5, 90],\n",
       " [3, 4, 11, 87, 29, 88, 29, 89, 29, 35, 5, 90, 6],\n",
       " [3, 4, 11, 87, 29, 88, 29, 89, 29, 35, 5, 90, 6, 91],\n",
       " [3, 4, 11, 87, 29, 88, 29, 89, 29, 35, 5, 90, 6, 91, 9],\n",
       " [3, 4, 11, 87, 29, 88, 29, 89, 29, 35, 5, 90, 6, 91, 9, 92],\n",
       " [3, 4, 11, 87, 29, 88, 29, 89, 29, 35, 5, 90, 6, 91, 9, 92, 2],\n",
       " [3, 4, 11, 87, 29, 88, 29, 89, 29, 35, 5, 90, 6, 91, 9, 92, 2, 41],\n",
       " [3, 4, 11, 87, 29, 88, 29, 89, 29, 35, 5, 90, 6, 91, 9, 92, 2, 41, 42],\n",
       " [3, 4, 11, 87, 29, 88, 29, 89, 29, 35, 5, 90, 6, 91, 9, 92, 2, 41, 42, 27],\n",
       " [43, 44],\n",
       " [43, 44, 3],\n",
       " [43, 44, 3, 30],\n",
       " [43, 44, 3, 30, 1],\n",
       " [43, 44, 3, 30, 1, 31],\n",
       " [43, 44, 3, 30, 1, 31, 2],\n",
       " [43, 44, 3, 30, 1, 31, 2, 93],\n",
       " [13, 19],\n",
       " [13, 19, 43],\n",
       " [13, 19, 43, 14],\n",
       " [13, 19, 43, 14, 45],\n",
       " [13, 19, 43, 14, 45, 20],\n",
       " [13, 19, 43, 14, 45, 20, 19],\n",
       " [13, 19, 43, 14, 45, 20, 19, 13],\n",
       " [13, 19, 43, 14, 45, 20, 19, 13, 2],\n",
       " [13, 19, 43, 14, 45, 20, 19, 13, 2, 31],\n",
       " [7, 46],\n",
       " [7, 46, 13],\n",
       " [7, 46, 13, 15],\n",
       " [7, 46, 13, 15, 94],\n",
       " [7, 46, 13, 15, 94, 95],\n",
       " [7, 46, 13, 15, 94, 95, 45],\n",
       " [7, 46, 13, 15, 94, 95, 45, 20],\n",
       " [7, 46, 13, 15, 94, 95, 45, 20, 2],\n",
       " [7, 46, 13, 15, 94, 95, 45, 20, 2, 12],\n",
       " [7, 46, 13, 15, 94, 95, 45, 20, 2, 12, 8],\n",
       " [7, 46, 13, 15, 94, 95, 45, 20, 2, 12, 8, 96],\n",
       " [7, 46, 13, 15, 94, 95, 45, 20, 2, 12, 8, 96, 97],\n",
       " [7, 46, 13, 15, 94, 95, 45, 20, 2, 12, 8, 96, 97, 3],\n",
       " [7, 46, 13, 15, 94, 95, 45, 20, 2, 12, 8, 96, 97, 3, 98],\n",
       " [7, 46, 13, 15, 94, 95, 45, 20, 2, 12, 8, 96, 97, 3, 98, 1],\n",
       " [7, 46, 13, 15, 94, 95, 45, 20, 2, 12, 8, 96, 97, 3, 98, 1, 99],\n",
       " [7, 46, 13, 15, 94, 95, 45, 20, 2, 12, 8, 96, 97, 3, 98, 1, 99, 2],\n",
       " [7, 46, 13, 15, 94, 95, 45, 20, 2, 12, 8, 96, 97, 3, 98, 1, 99, 2, 100],\n",
       " [47, 19],\n",
       " [47, 19, 12],\n",
       " [47, 19, 12, 31],\n",
       " [47, 19, 12, 31, 13],\n",
       " [47, 19, 12, 31, 13, 3],\n",
       " [47, 19, 12, 31, 13, 3, 21],\n",
       " [47, 19, 12, 31, 13, 3, 21, 101],\n",
       " [47, 19, 12, 31, 13, 3, 21, 101, 5],\n",
       " [47, 19, 12, 31, 13, 3, 21, 101, 5, 102],\n",
       " [47, 19, 12, 31, 13, 3, 21, 101, 5, 102, 5],\n",
       " [47, 19, 12, 31, 13, 3, 21, 101, 5, 102, 5, 103],\n",
       " [47, 19, 12, 31, 13, 3, 21, 101, 5, 102, 5, 103, 42],\n",
       " [104, 3],\n",
       " [104, 3, 22],\n",
       " [104, 3, 22, 11],\n",
       " [104, 3, 22, 11, 105],\n",
       " [104, 3, 22, 11, 105, 48],\n",
       " [104, 3, 22, 11, 105, 48, 49],\n",
       " [104, 3, 22, 11, 105, 48, 49, 50],\n",
       " [104, 3, 22, 11, 105, 48, 49, 50, 30],\n",
       " [104, 3, 22, 11, 105, 48, 49, 50, 30, 17],\n",
       " [14, 106],\n",
       " [14, 106, 20],\n",
       " [14, 106, 20, 25],\n",
       " [14, 106, 20, 25, 107],\n",
       " [14, 106, 20, 25, 107, 108],\n",
       " [25, 109],\n",
       " [25, 109, 34],\n",
       " [25, 109, 34, 3],\n",
       " [25, 109, 34, 3, 4],\n",
       " [25, 109, 34, 3, 4, 110],\n",
       " [25, 109, 34, 3, 4, 110, 10],\n",
       " [25, 109, 34, 3, 4, 110, 10, 111],\n",
       " [25, 109, 34, 3, 4, 110, 10, 111, 18],\n",
       " [47, 19],\n",
       " [47, 19, 112],\n",
       " [47, 19, 112, 3],\n",
       " [47, 19, 112, 3, 32],\n",
       " [47, 19, 112, 3, 32, 51],\n",
       " [47, 19, 112, 3, 32, 51, 23],\n",
       " [47, 19, 112, 3, 32, 51, 23, 10],\n",
       " [47, 19, 112, 3, 32, 51, 23, 10, 52],\n",
       " [47, 19, 112, 3, 32, 51, 23, 10, 52, 18],\n",
       " [3, 22],\n",
       " [3, 22, 113],\n",
       " [3, 22, 113, 1],\n",
       " [3, 22, 113, 1, 114],\n",
       " [3, 22, 113, 1, 114, 115],\n",
       " [3, 22, 113, 1, 114, 115, 116],\n",
       " [3, 22, 113, 1, 114, 115, 116, 2],\n",
       " [3, 22, 113, 1, 114, 115, 116, 2, 1],\n",
       " [3, 22, 113, 1, 114, 115, 116, 2, 1, 16],\n",
       " [3, 22, 113, 1, 114, 115, 116, 2, 1, 16, 8],\n",
       " [3, 22, 113, 1, 114, 115, 116, 2, 1, 16, 8, 117],\n",
       " [3, 22, 113, 1, 114, 115, 116, 2, 1, 16, 8, 117, 2],\n",
       " [3, 22, 113, 1, 114, 115, 116, 2, 1, 16, 8, 117, 2, 118],\n",
       " [3, 4],\n",
       " [3, 4, 10],\n",
       " [3, 4, 10, 119],\n",
       " [3, 4, 10, 119, 120],\n",
       " [3, 4, 10, 119, 120, 121],\n",
       " [3, 4, 10, 119, 120, 121, 122],\n",
       " [3, 4, 10, 119, 120, 121, 122, 8],\n",
       " [3, 4, 10, 119, 120, 121, 122, 8, 123],\n",
       " [3, 4, 10, 119, 120, 121, 122, 8, 123, 124],\n",
       " [9, 125],\n",
       " [9, 125, 126],\n",
       " [9, 125, 126, 22],\n",
       " [9, 125, 126, 22, 127],\n",
       " [9, 128],\n",
       " [9, 128, 22],\n",
       " [9, 128, 22, 129],\n",
       " [9, 128, 22, 129, 130],\n",
       " [9, 128, 22, 129, 130, 131],\n",
       " [9, 128, 22, 129, 130, 131, 132],\n",
       " [40, 3],\n",
       " [40, 3, 133],\n",
       " [40, 3, 133, 1],\n",
       " [40, 3, 133, 1, 33],\n",
       " [40, 3, 133, 1, 33, 134],\n",
       " [40, 3, 133, 1, 33, 134, 6],\n",
       " [40, 3, 133, 1, 33, 134, 6, 32],\n",
       " [40, 3, 133, 1, 33, 134, 6, 32, 51],\n",
       " [40, 3, 133, 1, 33, 134, 6, 32, 51, 23],\n",
       " [40, 3, 133, 1, 33, 134, 6, 32, 51, 23, 10],\n",
       " [40, 3, 133, 1, 33, 134, 6, 32, 51, 23, 10, 52],\n",
       " [40, 3, 133, 1, 33, 134, 6, 32, 51, 23, 10, 52, 18],\n",
       " [40, 3, 133, 1, 33, 134, 6, 32, 51, 23, 10, 52, 18, 33],\n",
       " [40, 3, 133, 1, 33, 134, 6, 32, 51, 23, 10, 52, 18, 33, 135],\n",
       " [40, 3, 133, 1, 33, 134, 6, 32, 51, 23, 10, 52, 18, 33, 135, 5],\n",
       " [40, 3, 133, 1, 33, 134, 6, 32, 51, 23, 10, 52, 18, 33, 135, 5, 33],\n",
       " [40, 3, 133, 1, 33, 134, 6, 32, 51, 23, 10, 52, 18, 33, 135, 5, 33, 136],\n",
       " [137, 12],\n",
       " [137, 12, 138],\n",
       " [7, 4],\n",
       " [7, 4, 10],\n",
       " [7, 4, 10, 139],\n",
       " [7, 4, 10, 139, 20],\n",
       " [15, 21],\n",
       " [15, 21, 140],\n",
       " [15, 21, 140, 53],\n",
       " [15, 21, 140, 53, 6],\n",
       " [15, 21, 140, 53, 6, 1],\n",
       " [15, 21, 140, 53, 6, 1, 16],\n",
       " [44, 7],\n",
       " [44, 7, 46],\n",
       " [44, 7, 46, 13],\n",
       " [44, 7, 46, 13, 141],\n",
       " [44, 7, 46, 13, 141, 15],\n",
       " [44, 7, 46, 13, 141, 15, 142],\n",
       " [44, 7, 46, 13, 141, 15, 142, 53],\n",
       " [44, 7, 46, 13, 141, 15, 142, 53, 6],\n",
       " [44, 7, 46, 13, 141, 15, 142, 53, 6, 1],\n",
       " [44, 7, 46, 13, 141, 15, 142, 53, 6, 1, 16],\n",
       " [44, 7, 46, 13, 141, 15, 142, 53, 6, 1, 16, 48],\n",
       " [44, 7, 46, 13, 141, 15, 142, 53, 6, 1, 16, 48, 49],\n",
       " [44, 7, 46, 13, 141, 15, 142, 53, 6, 1, 16, 48, 49, 50],\n",
       " [44, 7, 46, 13, 141, 15, 142, 53, 6, 1, 16, 48, 49, 50, 30],\n",
       " [44, 7, 46, 13, 141, 15, 142, 53, 6, 1, 16, 48, 49, 50, 30, 17],\n",
       " [54, 55],\n",
       " [54, 55, 143],\n",
       " [54, 55, 143, 55],\n",
       " [3, 21],\n",
       " [3, 21, 144],\n",
       " [3, 21, 144, 145],\n",
       " [3, 21, 144, 145, 11],\n",
       " [3, 21, 144, 145, 11, 54],\n",
       " [3, 21, 144, 145, 11, 54, 23],\n",
       " [3, 21, 144, 145, 11, 54, 23, 10],\n",
       " [3, 21, 144, 145, 11, 54, 23, 10, 146],\n",
       " [3, 21, 144, 145, 11, 54, 23, 10, 146, 56],\n",
       " [3, 21, 144, 145, 11, 54, 23, 10, 146, 56, 147],\n",
       " [3, 21, 144, 145, 11, 54, 23, 10, 146, 56, 147, 148],\n",
       " [3, 21, 144, 145, 11, 54, 23, 10, 146, 56, 147, 148, 23],\n",
       " [3, 21, 144, 145, 11, 54, 23, 10, 146, 56, 147, 148, 23, 149],\n",
       " [3, 21, 144, 145, 11, 54, 23, 10, 146, 56, 147, 148, 23, 149, 150],\n",
       " [3, 21, 144, 145, 11, 54, 23, 10, 146, 56, 147, 148, 23, 149, 150, 56],\n",
       " [151, 21],\n",
       " [151, 21, 152],\n",
       " [151, 21, 152, 57],\n",
       " [151, 21, 152, 57, 8],\n",
       " [151, 21, 152, 57, 8, 57],\n",
       " [14, 153],\n",
       " [14, 153, 154],\n",
       " [14, 153, 154, 28],\n",
       " [14, 153, 154, 28, 6],\n",
       " [14, 153, 154, 28, 6, 4],\n",
       " [14, 153, 154, 28, 6, 4, 58],\n",
       " [14, 153, 154, 28, 6, 4, 58, 59],\n",
       " [14, 153, 154, 28, 6, 4, 58, 59, 24],\n",
       " [14, 153, 154, 28, 6, 4, 58, 59, 24, 60],\n",
       " [14, 153, 154, 28, 6, 4, 58, 59, 24, 60, 39],\n",
       " [61, 155],\n",
       " [61, 155, 156],\n",
       " [61, 155, 156, 2],\n",
       " [61, 155, 156, 2, 1],\n",
       " [61, 155, 156, 2, 1, 157],\n",
       " [61, 155, 156, 2, 1, 157, 2],\n",
       " [61, 155, 156, 2, 1, 157, 2, 158],\n",
       " [61, 155, 156, 2, 1, 157, 2, 158, 159],\n",
       " [61, 155, 156, 2, 1, 157, 2, 158, 159, 160],\n",
       " [61, 155, 156, 2, 1, 157, 2, 158, 159, 160, 161],\n",
       " [61, 155, 156, 2, 1, 157, 2, 158, 159, 160, 161, 162],\n",
       " [61, 155, 156, 2, 1, 157, 2, 158, 159, 160, 161, 162, 163],\n",
       " [61, 155, 156, 2, 1, 157, 2, 158, 159, 160, 161, 162, 163, 164],\n",
       " [61, 155, 156, 2, 1, 157, 2, 158, 159, 160, 161, 162, 163, 164, 5],\n",
       " [61, 155, 156, 2, 1, 157, 2, 158, 159, 160, 161, 162, 163, 164, 5, 61],\n",
       " [61, 155, 156, 2, 1, 157, 2, 158, 159, 160, 161, 162, 163, 164, 5, 61, 165],\n",
       " [61,\n",
       "  155,\n",
       "  156,\n",
       "  2,\n",
       "  1,\n",
       "  157,\n",
       "  2,\n",
       "  158,\n",
       "  159,\n",
       "  160,\n",
       "  161,\n",
       "  162,\n",
       "  163,\n",
       "  164,\n",
       "  5,\n",
       "  61,\n",
       "  165,\n",
       "  166],\n",
       " [61,\n",
       "  155,\n",
       "  156,\n",
       "  2,\n",
       "  1,\n",
       "  157,\n",
       "  2,\n",
       "  158,\n",
       "  159,\n",
       "  160,\n",
       "  161,\n",
       "  162,\n",
       "  163,\n",
       "  164,\n",
       "  5,\n",
       "  61,\n",
       "  165,\n",
       "  166,\n",
       "  167],\n",
       " [61,\n",
       "  155,\n",
       "  156,\n",
       "  2,\n",
       "  1,\n",
       "  157,\n",
       "  2,\n",
       "  158,\n",
       "  159,\n",
       "  160,\n",
       "  161,\n",
       "  162,\n",
       "  163,\n",
       "  164,\n",
       "  5,\n",
       "  61,\n",
       "  165,\n",
       "  166,\n",
       "  167,\n",
       "  2],\n",
       " [61,\n",
       "  155,\n",
       "  156,\n",
       "  2,\n",
       "  1,\n",
       "  157,\n",
       "  2,\n",
       "  158,\n",
       "  159,\n",
       "  160,\n",
       "  161,\n",
       "  162,\n",
       "  163,\n",
       "  164,\n",
       "  5,\n",
       "  61,\n",
       "  165,\n",
       "  166,\n",
       "  167,\n",
       "  2,\n",
       "  168],\n",
       " [61,\n",
       "  155,\n",
       "  156,\n",
       "  2,\n",
       "  1,\n",
       "  157,\n",
       "  2,\n",
       "  158,\n",
       "  159,\n",
       "  160,\n",
       "  161,\n",
       "  162,\n",
       "  163,\n",
       "  164,\n",
       "  5,\n",
       "  61,\n",
       "  165,\n",
       "  166,\n",
       "  167,\n",
       "  2,\n",
       "  168,\n",
       "  169],\n",
       " [7, 28],\n",
       " [7, 28, 170],\n",
       " [7, 28, 170, 6],\n",
       " [7, 28, 170, 6, 4],\n",
       " [7, 28, 170, 6, 4, 58],\n",
       " [7, 28, 170, 6, 4, 58, 59],\n",
       " [7, 28, 170, 6, 4, 58, 59, 26],\n",
       " [7, 28, 170, 6, 4, 58, 59, 26, 24],\n",
       " [7, 28, 170, 6, 4, 58, 59, 26, 24, 2],\n",
       " [7, 28, 170, 6, 4, 58, 59, 26, 24, 2, 27],\n",
       " [7, 28, 170, 6, 4, 58, 59, 26, 24, 2, 27, 171],\n",
       " [7, 28, 170, 6, 4, 58, 59, 26, 24, 2, 27, 171, 5],\n",
       " [7, 28, 170, 6, 4, 58, 59, 26, 24, 2, 27, 171, 5, 172],\n",
       " [7, 28, 170, 6, 4, 58, 59, 26, 24, 2, 27, 171, 5, 172, 12],\n",
       " [7, 28, 170, 6, 4, 58, 59, 26, 24, 2, 27, 171, 5, 172, 12, 1],\n",
       " [7, 28, 170, 6, 4, 58, 59, 26, 24, 2, 27, 171, 5, 172, 12, 1, 60],\n",
       " [7, 28, 170, 6, 4, 58, 59, 26, 24, 2, 27, 171, 5, 172, 12, 1, 60, 173],\n",
       " [7, 28, 170, 6, 4, 58, 59, 26, 24, 2, 27, 171, 5, 172, 12, 1, 60, 173, 2],\n",
       " [7, 28, 170, 6, 4, 58, 59, 26, 24, 2, 27, 171, 5, 172, 12, 1, 60, 173, 2, 14],\n",
       " [7,\n",
       "  28,\n",
       "  170,\n",
       "  6,\n",
       "  4,\n",
       "  58,\n",
       "  59,\n",
       "  26,\n",
       "  24,\n",
       "  2,\n",
       "  27,\n",
       "  171,\n",
       "  5,\n",
       "  172,\n",
       "  12,\n",
       "  1,\n",
       "  60,\n",
       "  173,\n",
       "  2,\n",
       "  14,\n",
       "  41],\n",
       " [7, 32],\n",
       " [7, 32, 174],\n",
       " [7, 32, 174, 175],\n",
       " [7, 32, 174, 175, 8],\n",
       " [7, 32, 174, 175, 8, 14],\n",
       " [7, 32, 174, 175, 8, 14, 176]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d83efd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exacting max length of sequence in a sentence\n",
    "\n",
    "max_len = max([len(x) for x in input_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85b0af3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Padding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec7ac341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   7,   4],\n",
       "       [  0,   0,   0, ...,   7,   4,  24],\n",
       "       [  0,   0,   0, ...,   4,  24,  62],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 174, 175,   8],\n",
       "       [  0,   0,   0, ..., 175,   8,  14],\n",
       "       [  0,   0,   0, ...,   8,  14, 176]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5f828fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   0,   7],\n",
       "       [  0,   0,   0, ...,   0,   7,   4],\n",
       "       [  0,   0,   0, ...,   7,   4,  24],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  32, 174, 175],\n",
       "       [  0,   0,   0, ..., 174, 175,   8],\n",
       "       [  0,   0,   0, ..., 175,   8,  14]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = padded_input_sequences[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "867128c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(321, 28)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c9a1c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4,  24,  62,  25,  15,  63,  34,   2,   9,  35,  64,  36,  26,\n",
       "        37,   1,  16,   4,  65,   5,  66,  17,  67,   9,  68,  38,   9,\n",
       "        39,  69,  70,   1,  71,   1,  72,   1,  73,   1,  74,   1,  75,\n",
       "         1,  76,   1,  77,  26,   2,  27,  78,   5,  79,  17,  80,  37,\n",
       "        81,  28,  82,   3,   4,  11,  83,  12,   6,  84,  85,  18,   3,\n",
       "         4,  11,  38,  86,   4,  11,  87,  29,  88,  29,  89,  29,  35,\n",
       "         5,  90,   6,  91,   9,  92,   2,  41,  42,  27,  44,   3,  30,\n",
       "         1,  31,   2,  93,  19,  43,  14,  45,  20,  19,  13,   2,  31,\n",
       "        46,  13,  15,  94,  95,  45,  20,   2,  12,   8,  96,  97,   3,\n",
       "        98,   1,  99,   2, 100,  19,  12,  31,  13,   3,  21, 101,   5,\n",
       "       102,   5, 103,  42,   3,  22,  11, 105,  48,  49,  50,  30,  17,\n",
       "       106,  20,  25, 107, 108, 109,  34,   3,   4, 110,  10, 111,  18,\n",
       "        19, 112,   3,  32,  51,  23,  10,  52,  18,  22, 113,   1, 114,\n",
       "       115, 116,   2,   1,  16,   8, 117,   2, 118,   4,  10, 119, 120,\n",
       "       121, 122,   8, 123, 124, 125, 126,  22, 127, 128,  22, 129, 130,\n",
       "       131, 132,   3, 133,   1,  33, 134,   6,  32,  51,  23,  10,  52,\n",
       "        18,  33, 135,   5,  33, 136,  12, 138,   4,  10, 139,  20,  21,\n",
       "       140,  53,   6,   1,  16,   7,  46,  13, 141,  15, 142,  53,   6,\n",
       "         1,  16,  48,  49,  50,  30,  17,  55, 143,  55,  21, 144, 145,\n",
       "        11,  54,  23,  10, 146,  56, 147, 148,  23, 149, 150,  56,  21,\n",
       "       152,  57,   8,  57, 153, 154,  28,   6,   4,  58,  59,  24,  60,\n",
       "        39, 155, 156,   2,   1, 157,   2, 158, 159, 160, 161, 162, 163,\n",
       "       164,   5,  61, 165, 166, 167,   2, 168, 169,  28, 170,   6,   4,\n",
       "        58,  59,  26,  24,   2,  27, 171,   5, 172,  12,   1,  60, 173,\n",
       "         2,  14,  41,  32, 174, 175,   8,  14, 176])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = padded_input_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9afd9580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(321,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac83196a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7a8dbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y = to_categorical(y, num_classes = 177)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3eccef7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(321, 177)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1af190",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd214f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6abaec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(177, 100, input_length=28))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(177, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8890d45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bcd557b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 28, 100)           17700     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 150)               150600    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 177)               26727     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 195027 (761.82 KB)\n",
      "Trainable params: 195027 (761.82 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e8ff17dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\asus\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\asus\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "11/11 [==============================] - 5s 37ms/step - loss: 5.1680 - accuracy: 0.0405\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 5.0141 - accuracy: 0.0530\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 4.8931 - accuracy: 0.0498\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 4.8587 - accuracy: 0.0467\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 4.8294 - accuracy: 0.0530\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 4.8093 - accuracy: 0.0530\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 4.7927 - accuracy: 0.0561\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 4.7772 - accuracy: 0.0530\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 4.7600 - accuracy: 0.0467\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 4.7092 - accuracy: 0.0561\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 4.6685 - accuracy: 0.0654\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 4.5914 - accuracy: 0.0748\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 4.5216 - accuracy: 0.0810\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 4.4440 - accuracy: 0.0872\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 4.3786 - accuracy: 0.0966\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 4.2845 - accuracy: 0.0872\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 4.2110 - accuracy: 0.1153\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 4.1335 - accuracy: 0.1308\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 4.0552 - accuracy: 0.1153\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 3.9722 - accuracy: 0.1402\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 3.8751 - accuracy: 0.1620\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 3.7684 - accuracy: 0.1495\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 3.6835 - accuracy: 0.1589\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 3.5678 - accuracy: 0.1713\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 3.4501 - accuracy: 0.2118\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 3.3309 - accuracy: 0.1994\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 3.2650 - accuracy: 0.2118\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 3.1573 - accuracy: 0.2118\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 3.0160 - accuracy: 0.2492\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 2.8894 - accuracy: 0.3178\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 2.7768 - accuracy: 0.3146\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 2.7243 - accuracy: 0.3396\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 2.6217 - accuracy: 0.3583\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 2.5515 - accuracy: 0.3240\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 2.4527 - accuracy: 0.3925\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 2.3627 - accuracy: 0.4393\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 2.2618 - accuracy: 0.4798\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 2.1714 - accuracy: 0.4798\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 2.1018 - accuracy: 0.5016\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 2.0190 - accuracy: 0.5234\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 41ms/step - loss: 1.9304 - accuracy: 0.5296\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 1.8820 - accuracy: 0.5732\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 1.7927 - accuracy: 0.5919\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 1.7040 - accuracy: 0.6262\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 1.6507 - accuracy: 0.6355\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 1.5932 - accuracy: 0.6791\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 1.5363 - accuracy: 0.6916\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 1.4927 - accuracy: 0.7072\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 1.4541 - accuracy: 0.7040\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 1.3749 - accuracy: 0.7227\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 1.3311 - accuracy: 0.7290\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 39ms/step - loss: 1.2641 - accuracy: 0.7944\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 1.2070 - accuracy: 0.7757\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 1.1971 - accuracy: 0.8006\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 1.1705 - accuracy: 0.8069\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 1.1102 - accuracy: 0.8349\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 1.0690 - accuracy: 0.8255\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 1.0472 - accuracy: 0.8131\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 1.0254 - accuracy: 0.8193\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.9830 - accuracy: 0.8442\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.9449 - accuracy: 0.8474\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.8972 - accuracy: 0.8598\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.9052 - accuracy: 0.8598\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.8735 - accuracy: 0.8692\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.8834 - accuracy: 0.8660\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.8462 - accuracy: 0.8660\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.8002 - accuracy: 0.8598\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.7796 - accuracy: 0.8879\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.7466 - accuracy: 0.9034\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.6994 - accuracy: 0.9034\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.7075 - accuracy: 0.9003\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.7240 - accuracy: 0.8910\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.6928 - accuracy: 0.8660\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.6596 - accuracy: 0.9065\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.6120 - accuracy: 0.9159\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.5736 - accuracy: 0.9221\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.5448 - accuracy: 0.9190\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.5288 - accuracy: 0.9315\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.5125 - accuracy: 0.9346\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.4889 - accuracy: 0.9408\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.4714 - accuracy: 0.9470\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.4625 - accuracy: 0.9408\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.4766 - accuracy: 0.9377\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.4578 - accuracy: 0.9377\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.4392 - accuracy: 0.9377\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.4354 - accuracy: 0.9470\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.4275 - accuracy: 0.9439\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.4029 - accuracy: 0.9502\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.3861 - accuracy: 0.9564\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.3715 - accuracy: 0.9595\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.3624 - accuracy: 0.9533\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.3518 - accuracy: 0.9564\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.3500 - accuracy: 0.9564\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.3452 - accuracy: 0.9533\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 0.3362 - accuracy: 0.9595\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.3379 - accuracy: 0.9502\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.3630 - accuracy: 0.9533\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.3477 - accuracy: 0.9564\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.3361 - accuracy: 0.9439\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.3285 - accuracy: 0.9502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28f5f813010>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a066e6ce",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d49967fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n",
      "people from all onwards\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "people from all onwards the\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "people from all onwards the greeks\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "people from all onwards the greeks the\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "people from all onwards the greeks the turks\n"
     ]
    }
   ],
   "source": [
    "text = 'people from all'\n",
    "\n",
    "for i in range(5):\n",
    "   # tokenize\n",
    "    token_text = tokenizer.texts_to_sequences([text])[0]\n",
    "   # padding\n",
    "    padded_token_text = pad_sequences([token_text], maxlen = 28, padding='pre')\n",
    "   # predict \n",
    "    position = np.argmax(model.predict(padded_token_text))\n",
    "\n",
    "    for word,index in tokenizer.word_index.items():\n",
    "        if index == position:\n",
    "            text = text + \" \" + word\n",
    "            print(text)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "106c6520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0 15]]\n"
     ]
    }
   ],
   "source": [
    "print(padded_token_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66fc64a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9959b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
