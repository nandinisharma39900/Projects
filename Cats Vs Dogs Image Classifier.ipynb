{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a754f7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\asus\\anaconda3\\lib\\site-packages (1.5.16)\n",
      "Requirement already satisfied: bleach in c:\\users\\asus\\anaconda3\\lib\\site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\asus\\anaconda3\\lib\\site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\asus\\anaconda3\\lib\\site-packages (from kaggle) (2022.12.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\anaconda3\\lib\\site-packages (from kaggle) (4.64.1)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from kaggle) (1.26.14)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\asus\\anaconda3\\lib\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\lib\\site-packages (from kaggle) (2.28.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\asus\\anaconda3\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\anaconda3\\lib\\site-packages (from bleach->kaggle) (22.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->kaggle) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4192969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\asus\\anaconda3\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from opencv-python) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc50cd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "493aa2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Conv2D, Flatten, MaxPool2D, Activation\n",
    "from keras.utils import to_categorical\n",
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import image_dataset_from_directory \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img \n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory \n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbe9d9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The syntax of the command is incorrect.\n",
      "'cp' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "! mkdir -p ~/.kaggle\n",
    "! cp kaggle.json ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3797dc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\asus\\anaconda3\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\asus\\anaconda3\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\asus\\anaconda3\\Scripts\\kaggle.exe\\__main__.py\", line 4, in <module>\n",
      "  File \"C:\\Users\\asus\\anaconda3\\lib\\site-packages\\kaggle\\__init__.py\", line 23, in <module>\n",
      "    api.authenticate()\n",
      "  File \"C:\\Users\\asus\\anaconda3\\lib\\site-packages\\kaggle\\api\\kaggle_api_extended.py\", line 403, in authenticate\n",
      "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
      "OSError: Could not find kaggle.json. Make sure it's located in C:\\Users\\asus\\.kaggle. Or use the environment method.\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download - d salader/dogs-vs-cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b492af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data set has been extracted.\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile \n",
    "  \n",
    "data_path = \"C:/Users/asus/Downloads/Dogs-vs-Cats.zip\"\n",
    "  \n",
    "with ZipFile(data_path, 'r') as zip: \n",
    "    zip.extractall(\"C:/Users/asus/Downloads/Dogs-vs-Cats\") \n",
    "    print('The data set has been extracted.') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78739a84",
   "metadata": {},
   "source": [
    "# Data Preperation for TRaining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e1e1664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37500 files belonging to 2 classes.\n",
      "Using 33750 files for training.\n",
      "Found 37500 files belonging to 2 classes.\n",
      "Using 3750 files for validation.\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"C:/Users/asus/Downloads/Dogs-vs-Cats\"\n",
    "  \n",
    "# Create datasets \n",
    "train_datagen = image_dataset_from_directory(base_dir, \n",
    "                                                  image_size=(256,256), \n",
    "                                                  subset='training', \n",
    "                                                  seed = 1, \n",
    "                                                 validation_split=0.1, \n",
    "                                                  batch_size= 32) \n",
    "test_datagen = image_dataset_from_directory(base_dir, \n",
    "                                                  image_size=(256,256), \n",
    "                                                  subset='validation', \n",
    "                                                  seed = 1, \n",
    "                                                 validation_split=0.1, \n",
    "                                                  batch_size= 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c4cb901",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalizing \n",
    "\n",
    "def process(image, label):\n",
    "    image= tf.cast(image/255, tf.float32)\n",
    "    return image, label\n",
    "\n",
    "train_datagen = train_datagen.map(process)\n",
    "test_datagen = test_datagen.map(process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a020acb0",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d73282ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\asus\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\asus\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding=\"valid\", activation='relu', input_shape=(256,256,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=2, padding='valid'))\n",
    "\n",
    "model.add(Conv2D(64,kernel_size=(3,3),padding=\"valid\", activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=2, padding='valid'))\n",
    "\n",
    "model.add(Conv2D(128,kernel_size=(3,3),padding=\"valid\", activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=2, padding='valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2538894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 127, 127, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 62, 62, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 30, 30, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 115200)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               14745728  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14847297 (56.64 MB)\n",
      "Trainable params: 14847297 (56.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9048d409",
   "metadata": {},
   "source": [
    "# Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34abab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa83ccde",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd27104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1055/1055 [==============================] - 1864s 2s/step - loss: 0.6390 - accuracy: 0.6667 - val_loss: 0.6381 - val_accuracy: 0.6661\n",
      "Epoch 2/10\n",
      "1055/1055 [==============================] - 1769s 2s/step - loss: 0.6372 - accuracy: 0.6667 - val_loss: 0.6367 - val_accuracy: 0.6661\n",
      "Epoch 3/10\n",
      "1055/1055 [==============================] - 1478s 1s/step - loss: 0.6371 - accuracy: 0.6667 - val_loss: 0.6370 - val_accuracy: 0.6661\n",
      "Epoch 4/10\n",
      " 254/1055 [======>.......................] - ETA: 18:04 - loss: 0.6396 - accuracy: 0.6634"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_datagen, epochs=10, validation_data = test_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54259502",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], color='red', label='train')\n",
    "plt.plot(history.history['val_accuracy'], color='red', label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600100e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], color='red', label='train')\n",
    "plt.plot(history.history['val_loss'], color='red', label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df39122",
   "metadata": {},
   "source": [
    "# Model Testing and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1030b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image \n",
    "  \n",
    "#Input image \n",
    "test_image = image.load_img(\"C:/Users/asus/Downloads/cat image.avif\",target_size=(256,256)) \n",
    "  \n",
    "#For show image \n",
    "plt.imshow(test_image) \n",
    "test_image = image.img_to_array(test_image) \n",
    "test_image = np.expand_dims(test_image,axis=0) \n",
    "  \n",
    "# Result array \n",
    "result = model.predict(test_image) \n",
    "  \n",
    "#Mapping result array with the main name list \n",
    "i=0\n",
    "if(result>=0.5): \n",
    "    print(\"Dog\") \n",
    "else: \n",
    "    print(\"Cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36cc0ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd020902",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
